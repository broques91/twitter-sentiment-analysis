{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "from pymongo import MongoClient\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.types import StringType, StructType, StructField, FloatType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, udf\n",
    "from pyspark.ml.feature import RegexTokenizer\n",
    "from textblob import TextBlob\n",
    "from textblob_fr import PatternTagger, PatternAnalyzer\n",
    "\n",
    "import pymongo\n",
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cleanTweet(tweet: str) -> str:\n",
    "    tweet = re.sub(r'http\\S+', '', str(tweet))\n",
    "    tweet = re.sub(r'bit.ly/\\S+', '', str(tweet))\n",
    "    tweet = tweet.strip('[link]')\n",
    "\n",
    "    # enlever utilisateur\n",
    "    tweet = re.sub('(RT\\s@[A-Za-z]+[A-Za-z0-9-_]+)', '', str(tweet))\n",
    "    tweet = re.sub('(@[A-Za-z]+[A-Za-z0-9-_]+)', '', str(tweet))\n",
    "\n",
    "    # enlever ponctuation\n",
    "    my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~•@â'\n",
    "    tweet = re.sub('[' + my_punctuation + ']+', ' ', str(tweet))\n",
    "\n",
    "    # enlever les nombres\n",
    "    tweet = re.sub('([0-9]+)', '', str(tweet))\n",
    "\n",
    "    # enlever les hashtag\n",
    "    tweet = re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)', '', str(tweet))\n",
    "\n",
    "    return tweet\n",
    "\n",
    "def getSubjectivity(tweet: str) -> float:\n",
    "    return TextBlob(tweet, pos_tagger=PatternTagger(), analyzer=PatternAnalyzer()).sentiment[1]\n",
    "\n",
    "def getPolarity(tweet: str) -> float:\n",
    "    return TextBlob(tweet, pos_tagger=PatternTagger(), analyzer=PatternAnalyzer()).sentiment[0]\n",
    "\n",
    "def getSentiment(polarityValue: float) -> str:\n",
    "    if polarityValue < 0:\n",
    "        return 'Negative'\n",
    "    elif polarityValue == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "    \n",
    "\n",
    "spark = SparkSession\\\n",
    "            .builder\\\n",
    "            .master(\"local[2]\")\\\n",
    "            .appName(\"twitter_sentiment\")\\\n",
    "            .config('spark.mongodb.input.uri', 'mongodb://127.0.0.1:27017')\\\n",
    "            .config('spark.mongodb.output.uri', 'mongodb://127.0.0.1:27017')\\\n",
    "            .config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.1')\\\n",
    "            .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "tweets = spark\\\n",
    "          .readStream\\\n",
    "          .format(\"kafka\")\\\n",
    "          .option(\"kafka.bootstrap.servers\", \"localhost:9092,localhost:9093,localhost:9094\")\\\n",
    "          .option(\"subscribe\", \"twitter\")\\\n",
    "          .load()\n",
    "              \n",
    "\n",
    "mySchema = StructType([StructField(\"text\", StringType(), True)])\n",
    "values = tweets.select(from_json(tweets.value.cast(\"string\"), mySchema).alias(\"tweet\"))\n",
    "    \n",
    "    \n",
    "df1 = values.select(\"tweet.*\")\n",
    "\n",
    "\n",
    "clean_tweets = F.udf(cleanTweet, StringType())\n",
    "raw_tweets = df1.withColumn('processed_text', clean_tweets(col(\"text\")))\n",
    "    \n",
    "subjectivity = F.udf(getSubjectivity, FloatType())\n",
    "polarity = F.udf(getPolarity, FloatType())\n",
    "sentiment = F.udf(getSentiment, StringType())\n",
    "\n",
    "subjectivity_tweets = raw_tweets.withColumn('subjectivity', subjectivity(col(\"processed_text\")))\n",
    "polarity_tweets = subjectivity_tweets.withColumn(\"polarity\", polarity(col(\"processed_text\")))\n",
    "sentiment_tweets = polarity_tweets.withColumn(\"sentiment\", sentiment(col(\"polarity\")))\n",
    "\n",
    "\n",
    "def write_row_in_mongo(df):\n",
    "    myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "    mydb = myclient[\"te1\"]\n",
    "    mycol = mydb[\"coll\"]\n",
    "    mycol.insert_one(df.asDict())\n",
    "    pass\n",
    "\n",
    "sentiment_tweets.writeStream.foreach(write_row_in_mongo).start().awaitTermination()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
